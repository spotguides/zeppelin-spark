name: 'Zeppelin with Spark'
description: 'TODO write a description'
tags: ['Zeppelin', 'Spark']
resources:
  sumCpu: 8
  sumMem: 8
  filters: []
  sameSize: true
  onDemandPct: 50
  minNodes: 1
  maxNodes: 2
questions:
- type: pipeline
  dataType: string
  label: 'Namespace'
  required: true
  targets:
    - deploy_application.deployment.namespace
    - install_zeppelin_auth_secrets.clusterSecret.namespace
    - install_history_server_bucket_secrets.clusterSecret.namespace
    - install_history_server_auth_secrets.clusterSecret.namespace
    - deploy_application.deployment.values.zeppelin-spark.zeppelin.sparkSubmitOptions.k8sNameSpace
- type: secret
  dataType: password
  name: zeppelinpass
  required: true
  label: 'Zeppelin server auth credentials'
  targets:
    - name: install_zeppelin_auth_secrets.clusterSecret.sourceSecretName
    - name: deploy_application.deployment.values.banzaicloud.secret.zeppelin
- type: pipeline
  dataType: enum
  key: spark_version_enum
  label: 'Spark Version'
  description: ''
  default: '2.4.3'
  required: true
  options:
  - '2.3.2'
  - '2.4.3'
  targets:
  - deploy_application.deployment.values.banzaicloud.spark.version
- type: pipeline
  dataType: boolean
  default: true
  label: 'Spark History Server'
  required: true
  key: historyServer
  targets:
    - deploy_application.deployment.values.historyServer.enabled
- type: secret
  dataType: htpasswd
  name: historyserverpass
  label: 'History Server Auth Creds'
  required: true
  showIf:
    properties:
      historyServer:
        const: true
  targets:
    - name: install_history_server_auth_secrets.clusterSecret.sourceSecretName
    - name: deploy_application.deployment.values.banzaicloud.secret.historyServer
- type: bucket
  name: eventBucket
  label: 'Spark Event Log Bucket Name'
  description: 'This bucket will be used to store spark logs.'
  required: true
  showIf:
    properties:
      historyServer:
        const: true
  targets:
    - name: deploy_application.deployment.values.zeppelin-spark.spark.spark-hs.sparkEventLogStorage.logDirectory
    - name: deploy_application.deployment.values.zeppelin-spark.zeppelin.sparkEventLogStorage.logDirectory
    - cloud: deploy_application.deployment.values.zeppelin-spark.spark.spark-hs.sparkEventLogStorage.cloudProvider
    - cloud: deploy_application.deployment.values.zeppelin-spark.zeppelin.sparkEventLogStorage.cloudProvider
    - location: deploy_application.deployment.values.zeppelin-spark.spark.spark-hs.sparkEventLogStorage.aliOssRegion
    - location: deploy_application.deployment.values.zeppelin-spark.spark.spark-hs.sparkEventLogStorage.oracleRegion
    - location: deploy_application.deployment.values.zeppelin-spark.zeppelin.sparkEventLogStorage.aliOssRegion
    - location: deploy_application.deployment.values.zeppelin-spark.zeppelin.sparkEventLogStorage.oracleRegion
    - secret.accessName: install_history_server_bucket_secrets.clusterSecret.sourceSecretName
    - secret.accessName: deploy_application.deployment.values.zeppelin-spark.spark.spark-hs.sparkEventLogStorage.pipelineSecretName
    - aks.storageAccount: deploy_application.deployment.values.zeppelin-spark.spark.spark-hs.sparkEventLogStorage.azureStorageAccountName
    - oracle.namespace: deploy_application.deployment.values.zeppelin-spark.zeppelin.sparkEventLogStorage.oracleNamespace
    - oracle.namespace: deploy_application.deployment.values.zeppelin-spark.spark.spark-hs.sparkEventLogStorage.oracleNamespace
- type: pipeline
  dataType: boolean
  label: "Spark Monitoring"
  required: true
  key: monitoring
  default: true
  targets:
    - deploy_application.deployment.values.zeppelin-spark.spark.monitoring.enabled
- type: pipeline
  dataType: string
  controlType: code
  config:
    mode: properties
  label: 'Metrics properties'
  required: false
  default: |
    # Enable Prometheus for all instances by class name
    *.sink.prometheus.class=com.banzaicloud.spark.metrics.sink.PrometheusSink
    # Prometheus pushgateway address
    *.sink.prometheus.pushgateway-address=prometheus-pushgateway.pipeline-system:9091
    *.sink.prometheus.pushgateway-enable-timestamp=true
    *.sink.prometheus.enable-dropwizard-collector=false
    *.sink.prometheus.enable-jmx-collector=true
    *.sink.prometheus.jmx-collector-config=/opt/spark/conf/monitoring/jmxCollector.yaml
    *.sink.jmx.class=org.apache.spark.metrics.sink.JmxSink
    # Enable JVM metrics source for all instances by class name
    *.source.jvm.class=org.apache.spark.metrics.source.JvmSource
  showIf:
    properties:
      monitoring:
        const: true
  targets:
    - deploy_application.deployment.values.zeppelin-spark.spark.monitoring.metricsProperties
- type: pipeline
  dataType: string
  controlType: code
  config:
    mode: yaml
  label: 'JMX collector'
  required: false
  default: |
    lowercaseOutputName: false
    lowercaseOutputLabelNames: false
    whitelistObjectNames: ["*:*"]
  showIf:
    properties:
      monitoring:
        const: true
  targets:
    - deploy_application.deployment.values.zeppelin-spark.spark.monitoring.jmxCollector
